{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To create an image classifier that differentiates between normal faces and those of individuals with stroke or neurological disorders using Mediapipe for landmark extraction, follow this step-by-step guide. This approach will focus on using landmarks extracted by Mediapipe to classify images, instead of employing traditional machine learning models like SVMs (Support Vector Machines) or CNNs (Convolutional Neural Networks).\n",
        "\n",
        "# **Step 1: Setup Your Environment**\n",
        "First, ensure you have all the required libraries installed. You'll need OpenCV, Mediapipe, and any additional libraries for data handling and processing (like NumPy and Pandas). The code snippet you provided is a good starting point for setting up Mediapipe and capturing video frames. For image classification, however, we'll adapt it to process a dataset of images."
      ],
      "metadata": {
        "id": "5FfkUGsds9jc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Load Your Dataset**\n",
        "Load the dataset of 600 images, ensuring that you have labels for each image indicating whether it's a normal face or a stroke/neurologically disordered face. Organize your images and labels in a manner that's easy to access and iterate over, possibly using a structured directory format or a CSV file to map images to their labels."
      ],
      "metadata": {
        "id": "M5kCbSqEs9l8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step A: Organize Your Dataset**\n",
        "\n",
        "First, ensure your dataset is well-organized. A common approach is to have separate folders for each category. For instance:\n",
        "\n",
        "dataset/\n",
        "\n",
        "normal/ (contains 300 images of normal faces)\n",
        "\n",
        "stroke/ (contains 300 images of faces with stroke or neurological disorders)\n",
        "\n",
        "# **Step B: Install Required Libraries**\n",
        "\n",
        "Make sure you have the necessary Python libraries installed. You'll need opencv-python for image processing and numpy for handling arrays. You can install them using pip:"
      ],
      "metadata": {
        "id": "vhe__2bPs9oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python numpy\n",
        "pip install mediapipe"
      ],
      "metadata": {
        "id": "HCC9D0eNtmep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Load and Label the Images**\n",
        "\n",
        "You will write a function to load the images from each directory, convert them into a suitable format (e.g., a NumPy array), and label them appropriately. Here's an example script that does this:"
      ],
      "metadata": {
        "id": "Kni1HpZ9s9rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Function to load images from a directory\n",
        "def load_images_from_folder(folder, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "# Load dataset\n",
        "normal_images, normal_labels = load_images_from_folder('dataset/normal', 0)  # 0 for 'normal'\n",
        "stroke_images, stroke_labels = load_images_from_folder('dataset/stroke', 1)  # 1 for 'stroke'\n",
        "\n",
        "# Combine datasets\n",
        "all_images = normal_images + stroke_images\n",
        "all_labels = normal_labels + stroke_labels\n",
        "\n",
        "# Convert to numpy arrays for processing\n",
        "all_images = np.array(all_images)\n",
        "all_labels = np.array(all_labels)\n"
      ],
      "metadata": {
        "id": "vU0BXNEdt8yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4: Preprocess the Images**\n",
        "\n",
        "Depending on your specific requirements (e.g., the input size of your classification model), you may need to resize the images to ensure they are of uniform size:"
      ],
      "metadata": {
        "id": "dI4g-fIwuDdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to resize images\n",
        "def resize_images(images, size=(224, 224)):\n",
        "    resized_images = []\n",
        "    for img in images:\n",
        "        img = cv2.resize(img, size)\n",
        "        resized_images.append(img)\n",
        "    return np.array(resized_images)\n",
        "\n",
        "# Resize all images\n",
        "all_images_resized = resize_images(all_images)\n"
      ],
      "metadata": {
        "id": "rHXzm98KuYlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Split the Dataset**\n",
        "\n",
        "It's essential to split your dataset into training and testing (and possibly validation) sets. This helps evaluate the performance of your model on unseen data. You can use train_test_split from sklearn.model_selection for this purpose:"
      ],
      "metadata": {
        "id": "3SXzy9TFs9uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(all_images_resized, all_labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "huEJwKd-ulAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Preprocessing the landmarks extracted from images and performing feature engineering are critical steps in preparing your data for training a classifier. This process involves transforming raw facial landmarks into meaningful features that a machine learning model can use to differentiate between normal faces and those affected by stroke or neurological disorders. Below, I'll guide you through the preprocessing and feature engineering stages using the landmarks extracted via Mediapipe.\n",
        "\n",
        "# **Preprocessing Landmarks**\n",
        "Preprocessing involves standardizing the format and scale of your landmark data to make it suitable for feature engineering and model training.\n",
        "\n",
        "**Normalization**:\n",
        "Normalize landmark coordinates to ensure they are scale-invariant. This can be particularly important if the images vary in size or if the faces are at different distances from the camera.\n",
        "\n",
        "Alignment: Optionally, you might align the faces based on specific landmarks (e.g., the eyes) to reduce variability due to head pose."
      ],
      "metadata": {
        "id": "FhT_TZmKs9wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize_landmarks(landmarks):\n",
        "    # Assuming landmarks is a NumPy array of shape (num_landmarks, 3) for (x, y, z) coordinates\n",
        "    mean = np.mean(landmarks, axis=0)\n",
        "    std = np.std(landmarks, axis=0)\n",
        "    normalized_landmarks = (landmarks - mean) / std\n",
        "    return normalized_landmarks\n"
      ],
      "metadata": {
        "id": "IXMXyRzdvXbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**\n",
        "Feature engineering involves creating meaningful features from the normalized landmarks that can help distinguish between normal and stroke faces. This might include metrics of asymmetry, distances between specific points, angles, or other statistical features derived from the landmark positions.\n",
        "\n",
        "Asymmetry Features: Stroke often causes facial asymmetry. Calculate asymmetry by comparing the distances between corresponding landmarks on the left and right sides of the face.\n",
        "\n",
        "Key Distances: Measure distances between key points, such as the width of the mouth, the height of the eyes, and the distance between eyebrows. Changes in these distances might indicate neurological disorders.\n",
        "\n",
        "Statistical Features: Compute statistical measures like the mean, median, standard deviation, and variance of the landmark coordinates or the distances/angles between landmarks.\n",
        "\n",
        "Here's an example of calculating a simple feature - the distance between two points (which could represent the eye corners, for example):"
      ],
      "metadata": {
        "id": "nU7HoBssvd-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_distance(point1, point2):\n",
        "    # Assuming point1 and point2 are (x, y, z) coordinates\n",
        "    return np.sqrt(np.sum((point1 - point2) ** 2))\n",
        "\n",
        "# Example usage\n",
        "# Calculate the distance between two landmarks\n",
        "distance_example = calculate_distance(landmarks[0], landmarks[1])\n"
      ],
      "metadata": {
        "id": "KqKykZo2vjEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Combining Features into a Dataset**\n",
        "Once you've engineered your features, combine them into a structured format (like a NumPy array or Pandas DataFrame) along with the corresponding labels for each image. This dataset is what you'll use to train your model."
      ],
      "metadata": {
        "id": "AzRbHfeQvWef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have a list of feature vectors and their corresponding labels\n",
        "features = [feature_vector1, feature_vector2, ...]  # Your engineered features for each image\n",
        "labels = [0, 1, ...]  # 0 for normal, 1 for stroke\n",
        "\n",
        "# Convert to DataFrame for easy manipulation\n",
        "df = pd.DataFrame(features)\n",
        "df['label'] = labels\n"
      ],
      "metadata": {
        "id": "5nn-AaufwGCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tips for Effective Feature Engineering**\n",
        "Exploration is Key: Experiment with different features and combinations thereof. The effectiveness of features can vary depending on the specifics of the dataset and the task.\n",
        "Dimensionality Reduction: If you end up with a high number of features, consider using techniques like PCA (Principal Component Analysis) to reduce dimensionality while retaining the most informative aspects of your data.\n",
        "Iterate and Validate: Continuously validate the effectiveness of your features by training models and evaluating their performance. Use this feedback to refine or develop new features.\n",
        "The goal of these steps is to transform the raw facial landmarks into a set of features that effectively capture the differences between normal faces and those affected by stroke or neurological conditions, thereby enabling accurate classification."
      ],
      "metadata": {
        "id": "H8R-gifTwKZj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step : Train Your Model**\n",
        "Here's how you can train a Random Forest model using scikit-learn:"
      ],
      "metadata": {
        "id": "iX__9mkEwP8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the model\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "ZlbZxRUOwPgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Evaluate the Model**\n",
        "After training, you evaluate the model using the test set:\n",
        "\n"
      ],
      "metadata": {
        "id": "7RPR4BDRxwhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "id": "bzsrOIxUxscn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing Image Classification with MediaPipe and Training the Model\n",
        "To tie everything together for your specific use case:\n",
        "\n",
        "Extract Landmarks: Use MediaPipe to extract facial landmarks from your images, as discussed earlier.\n",
        "\n",
        "Preprocess and Feature Engineering: Preprocess these landmarks to normalize them, then engineer features that can discriminate between normal and stroke-affected faces.\n",
        "\n",
        "Prepare Your Dataset: Combine your engineered features into a structured dataset with labels.\n",
        "\n",
        "Follow Steps 3-5: Split your dataset, choose a machine learning model, train it, and evaluate its performance."
      ],
      "metadata": {
        "id": "bJh8bNjpx44O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming features and labels are prepared\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "FGA5VXkPx_p_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}